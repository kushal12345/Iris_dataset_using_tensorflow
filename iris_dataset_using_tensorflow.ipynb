{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal length (cm)',\n",
       " 'sepal width (cm)',\n",
       " 'petal length (cm)',\n",
       " 'petal width (cm)']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['feature_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['target_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare to create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 4\n",
    "hidden_dim = 5\n",
    "output_dim = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printtensor(inputx,feedx,feedy):\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        out = print(sess.run(inputx,feed_dict={X:feedx,y:feedy}))\n",
    "        sess.close()\n",
    "    return out   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X  = tf.placeholder(shape=(None,input_dim),dtype=tf.float64)\n",
    "y  = tf.placeholder(shape=(None,output_dim),dtype=tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x,test_x,train_y,test_y = train_test_split(data.data, data.target, test_size=0.33, random_state=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_y = train_y.reshape(-1,1)\n",
    "test_y = test_y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 4)\n",
      "(100,)\n",
      "(50, 4)\n",
      "(50,)\n",
      "(?, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_train = tf.one_hot(train_y,3,dtype=tf.float64)\n",
    "one_hot_test = tf.one_hot(test_y,3,dtype=tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ih_wts = tf.Variable(tf.random_normal([input_dim,hidden_dim], dtype=tf.float64))\n",
    "h_biases = tf.Variable(1.0, dtype=tf.float64)\n",
    "ho_wts = tf.Variable(tf.random_normal([hidden_dim,output_dim], dtype=tf.float64))\n",
    "o_biases = tf.Variable(1.0, dtype=tf.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  define model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = tf.nn.sigmoid(tf.add(tf.matmul(X,ih_wts),h_biases))\n",
    "output = tf.nn.sigmoid(tf.add(tf.matmul(hidden,ho_wts),o_biases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hidden = tf.layers.dense(a, 5, tf.nn.relu, name=\"hidden\")\n",
    "#output = tf.layers.dense(hidden, 3, tf.nn.relu, name=\"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = tf.argmax(output,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_rate = 0.001\n",
    "max_epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost= tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=one_hot_train, logits=output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learn_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training\n",
      "====================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/site-packages/ipykernel_launcher.py:17: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =   10, train accuracy = 0.4064 \n",
      "epoch =   20, train accuracy = 0.4063 \n",
      "epoch =   30, train accuracy = 0.4063 \n",
      "epoch =   40, train accuracy = 0.4062 \n",
      "epoch =   50, train accuracy = 0.4062 \n",
      "epoch =   60, train accuracy = 0.4061 \n",
      "epoch =   70, train accuracy = 0.4060 \n",
      "epoch =   80, train accuracy = 0.4060 \n",
      "epoch =   90, train accuracy = 0.4059 \n",
      "epoch =  100, train accuracy = 0.4059 \n",
      "epoch =  110, train accuracy = 0.4058 \n",
      "epoch =  120, train accuracy = 0.4057 \n",
      "epoch =  130, train accuracy = 0.4057 \n",
      "epoch =  140, train accuracy = 0.4056 \n",
      "epoch =  150, train accuracy = 0.4056 \n",
      "epoch =  160, train accuracy = 0.4055 \n",
      "epoch =  170, train accuracy = 0.4054 \n",
      "epoch =  180, train accuracy = 0.4054 \n",
      "epoch =  190, train accuracy = 0.4053 \n",
      "====================================\n",
      "Training complete \n",
      "\n",
      "====================================\n",
      "Cost for training data: 1.0966563901859967\n",
      "====================================\n",
      "Accuracy on test data = 0.4052 \n",
      "====================================\n",
      "\n",
      "End demo\n",
      "====================================\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "            sess.run(init)\n",
    "            print(\"Starting training\")\n",
    "            print(\"====================================\")\n",
    "            for epoch in range(max_epochs):\n",
    "                indices = np.arange(len(train_x))\n",
    "                #convering tensor into array\n",
    "                train_y_array=one_hot_train.eval()\n",
    "                test_y_array=one_hot_test.eval()\n",
    "                y_predict_float = tf.cast(output,dtype=tf.float64)\n",
    "                #print(y_predict_float.shape)\n",
    "                for ii in range(len(indices)):\n",
    "                    i = indices[ii]\n",
    "                    sess.run(optimizer,feed_dict={X:train_x[i:i+1],y:train_y_array[i:i+1]})\n",
    "                    #printtensor(optimizer,train_x,train_y_array)\n",
    "                #train_acc = np.mean(train_y_array-y_predict)\n",
    "                train_calc = np.argmax(train_y_array, axis=1) == sess.run(y_predict_float, feed_dict={X: train_x, y: train_y_array})\n",
    "                #print(train_calc)\n",
    "                train_acc = np.mean(-train_y_array + sess.run(y_predict_float, feed_dict={X: train_x, y: train_y_array}))                \n",
    "                if epoch > 0 and epoch % 10 == 0:\n",
    "                    print(\"epoch = %4d, train accuracy = %.4f \" % (epoch, train_acc))\n",
    "            print(\"====================================\")\n",
    "            print(\"Training complete \\n\")\n",
    "            print(\"====================================\")\n",
    "            print(\"Cost for training data:\",sess.run(cost, feed_dict={X:train_x, y:train_y_array}))\n",
    "            print(\"====================================\")\n",
    "            test_acc = np.mean(-test_y_array + sess.run(y_predict_float, feed_dict={X:test_x, y:test_y_array}))\n",
    "            print(\"Accuracy on test data = %.4f \" % test_acc)\n",
    "            sess.close()\n",
    "            print(\"====================================\")\n",
    "            print(\"\\nEnd demo\")\n",
    "            print(\"====================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
